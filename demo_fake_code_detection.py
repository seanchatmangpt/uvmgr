#!/usr/bin/env python3
"""
Demonstration of Fake Code Detection System

This script demonstrates how the uvmgr validation system can detect
fake or hallucinated code generated by AI assistants like Claude Code.
"""

import json
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Tuple

# Add the src directory to the path to import uvmgr modules
sys.path.insert(0, str(Path(__file__).parent / "src"))

try:
    from uvmgr.core.validation import (
        ValidationLevel, ValidationResult, HallucinationDetector,
        MLBasedDetector, BehavioralAnalyzer, ValidationOrchestrator
    )
    UVMGR_AVAILABLE = True
except ImportError:
    print("âš ï¸  uvmgr validation modules not available, using simplified demo")
    UVMGR_AVAILABLE = False
    # Fallback to simplified versions for demo purposes
    from enum import Enum
    
    class ValidationLevel(Enum):
        BASIC = "basic"
        STRICT = "strict"
        PARANOID = "paranoid"
    
    class ValidationResult:
        def __init__(self, is_valid: bool, confidence: float, issues: List[str], 
                     metadata: Dict[str, Any], validation_level: ValidationLevel):
            self.is_valid = is_valid
            self.confidence = max(0.0, min(1.0, confidence))
            self.issues = issues
            self.metadata = metadata
            self.validation_level = validation_level
    
    class SimplifiedDetector:
        def __init__(self):
            self.suspicious_patterns = [
                "lorem ipsum", "test data", "placeholder", "sample", "example",
                "dummy", "fake", "mock", "stub", "TODO", "FIXME", "XXX", "TBD",
                "random", "generated", "synthetic"
            ]
        
        def detect_hallucinations(self, data: Any) -> Tuple[float, List[str]]:
            issues = []
            score = 0.0
            
            if isinstance(data, str):
                for pattern in self.suspicious_patterns:
                    if pattern.lower() in data.lower():
                        issues.append(f"Suspicious pattern: {pattern}")
                        score += 0.3
            
            elif isinstance(data, dict):
                for key, value in data.items():
                    if isinstance(value, str):
                        for pattern in self.suspicious_patterns:
                            if pattern.lower() in value.lower():
                                issues.append(f"Suspicious pattern in {key}: {pattern}")
                                score += 0.3
            
            return min(1.0, score), issues
        
        def analyze_response_pattern(self, data: Any, context: Dict[str, Any]) -> Tuple[float, List[str]]:
            return self.detect_hallucinations(data)
    
    HallucinationDetector = SimplifiedDetector
    MLBasedDetector = SimplifiedDetector
    BehavioralAnalyzer = SimplifiedDetector
    ValidationOrchestrator = SimplifiedDetector


class FakeCodeDetector:
    """Demonstration class for detecting fake code and hallucinations."""
    
    def __init__(self):
        if UVMGR_AVAILABLE:
            self.detector = HallucinationDetector(ValidationLevel.STRICT)
            self.ml_detector = MLBasedDetector()
            self.behavioral_analyzer = BehavioralAnalyzer()
            self.orchestrator = ValidationOrchestrator(ValidationLevel.STRICT)
        else:
            self.detector = HallucinationDetector()
            self.ml_detector = MLBasedDetector()
            self.behavioral_analyzer = BehavioralAnalyzer()
            self.orchestrator = ValidationOrchestrator()
    
    def analyze_code_sample(self, code_sample: Dict[str, Any], 
                          context: str = "code generation") -> ValidationResult:
        """Analyze a code sample for potential hallucinations."""
        print(f"\nğŸ” Analyzing {context}...")
        print(f"Sample: {json.dumps(code_sample, indent=2)}")
        
        if UVMGR_AVAILABLE:
            # Use the actual uvmgr validation system
            return self._analyze_with_uvmgr(code_sample, context)
        else:
            # Use simplified validation
            return self._analyze_simplified(code_sample, context)
    
    def _analyze_with_uvmgr(self, code_sample: Dict[str, Any], context: str) -> ValidationResult:
        """Analyze using the actual uvmgr validation system."""
        # Use the workflow run validation as a general-purpose validator
        result = self.detector.validate_workflow_run(code_sample, {"context": context})
        self._print_analysis_result(result)
        return result
    
    def _analyze_simplified(self, code_sample: Dict[str, Any], context: str) -> ValidationResult:
        """Analyze using simplified validation for demo purposes."""
        # Multi-layered validation
        issues = []
        confidence = 1.0
        
        # 1. Basic pattern detection
        pattern_score, pattern_issues = self.detector.detect_hallucinations(code_sample)
        if pattern_issues:
            issues.extend(pattern_issues)
            confidence -= pattern_score * 0.4
        
        # 2. ML-based detection
        ml_score, ml_issues = self.ml_detector.detect_hallucinations(code_sample)
        if ml_issues:
            issues.extend(ml_issues)
            confidence -= ml_score * 0.3
        
        # 3. Behavioral analysis
        behavior_score, behavior_issues = self.behavioral_analyzer.analyze_response_pattern(
            code_sample, {"context": context}
        )
        if behavior_issues:
            issues.extend(behavior_issues)
            confidence -= behavior_score * 0.2
        
        # 4. Field validation
        field_issues = self._validate_fields(code_sample)
        if field_issues:
            issues.extend(field_issues)
            confidence -= len(field_issues) * 0.1
        
        result = ValidationResult(
            is_valid=confidence > 0.5,
            confidence=max(0.0, confidence),
            issues=issues,
            metadata={
                "pattern_score": pattern_score,
                "ml_score": ml_score,
                "behavior_score": behavior_score,
                "context": context
            },
            validation_level=ValidationLevel.STRICT
        )
        
        self._print_analysis_result(result)
        return result
    
    def _validate_fields(self, data: Dict[str, Any]) -> List[str]:
        """Validate specific fields for common issues."""
        issues = []
        
        # Check for common fake code indicators
        if "name" in data:
            name = str(data["name"]).lower()
            if any(pattern in name for pattern in ["test", "example", "sample", "dummy"]):
                issues.append("Suspicious name pattern")
        
        if "description" in data:
            desc = str(data["description"]).lower()
            if any(pattern in desc for pattern in ["placeholder", "TODO", "FIXME"]):
                issues.append("Placeholder description detected")
        
        if "id" in data:
            if not str(data["id"]).isdigit():
                issues.append("Invalid ID format")
        
        return issues
    
    def _print_analysis_result(self, result: ValidationResult):
        """Print analysis results in a formatted way."""
        status = "âœ… VALID" if result.is_valid else "âŒ INVALID"
        confidence_pct = result.confidence * 100
        
        print(f"\nğŸ“Š Analysis Results:")
        print(f"   Status: {status}")
        print(f"   Confidence: {confidence_pct:.1f}%")
        print(f"   Validation Level: {result.validation_level.value}")
        
        if result.issues:
            print(f"   Issues Found ({len(result.issues)}):")
            for i, issue in enumerate(result.issues, 1):
                print(f"     {i}. {issue}")
        else:
            print("   âœ… No issues detected")
        
        if result.metadata:
            print(f"   Metadata: {result.metadata}")


def demonstrate_fake_code_detection():
    """Demonstrate the fake code detection system with various examples."""
    
    detector = FakeCodeDetector()
    
    print("ğŸš€ Claude Code Fake Code Detection Demonstration")
    print("=" * 60)
    
    # Example 1: Valid GitHub Actions workflow run
    print("\nğŸ“‹ Example 1: Valid GitHub Actions Workflow Run")
    valid_workflow = {
        "id": 123456789,
        "name": "CI/CD Pipeline",
        "status": "completed",
        "conclusion": "success",
        "event": "push",
        "head_branch": "main",
        "created_at": "2024-01-15T10:30:00Z",
        "updated_at": "2024-01-15T10:35:00Z",
        "html_url": "https://github.com/owner/repo/actions/runs/123456789"
    }
    detector.analyze_code_sample(valid_workflow, "GitHub Actions workflow run")
    
    # Example 2: Fake workflow run with suspicious patterns
    print("\nğŸ“‹ Example 2: Fake Workflow Run (Suspicious Patterns)")
    fake_workflow = {
        "id": "not_a_number",
        "name": "lorem ipsum pipeline",
        "status": "invalid_status",
        "conclusion": "success",
        "event": "push",
        "head_branch": "main",
        "created_at": "invalid_timestamp",
        "description": "This is a placeholder workflow for testing purposes"
    }
    detector.analyze_code_sample(fake_workflow, "Fake GitHub Actions workflow run")
    
    # Example 3: Generated code with suspicious names
    print("\nğŸ“‹ Example 3: Generated Code with Suspicious Names")
    suspicious_code = {
        "id": 123,
        "name": "test_example_function",
        "status": "completed",
        "description": "TODO: Implement this function properly",
        "parameters": ["placeholder_param1", "dummy_param2"]
    }
    detector.analyze_code_sample(suspicious_code, "Generated code with suspicious names")
    
    # Example 4: Valid code structure
    print("\nğŸ“‹ Example 4: Valid Code Structure")
    valid_code = {
        "id": 456,
        "name": "process_user_data",
        "status": "completed",
        "description": "Process user data and return formatted results",
        "parameters": ["user_id", "data_format"]
    }
    detector.analyze_code_sample(valid_code, "Valid code structure")
    
    # Example 5: Future timestamp detection
    print("\nğŸ“‹ Example 5: Future Timestamp Detection")
    future_data = {
        "id": 987654321,
        "name": "Future Pipeline",
        "status": "completed",
        "created_at": "2025-12-31T23:59:59Z",  # Future timestamp
        "description": "This pipeline runs in the future"
    }
    detector.analyze_code_sample(future_data, "Data with future timestamps")
    
    # Example 6: Repetitive pattern detection
    print("\nğŸ“‹ Example 6: Repetitive Pattern Detection")
    repetitive_data = {
        "id": 789,
        "name": "Test Workflow Series",
        "status": "completed",
        "description": "This is a test workflow with repetitive patterns",
        "workflows": [
            {"id": 1, "name": "Test Workflow 1", "status": "completed"},
            {"id": 2, "name": "Test Workflow 2", "status": "completed"},
            {"id": 3, "name": "Test Workflow 3", "status": "completed"}
        ]
    }
    detector.analyze_code_sample(repetitive_data, "Repetitive pattern data")


def demonstrate_validation_levels():
    """Demonstrate different validation levels."""
    
    print("\nğŸ”§ Validation Levels Demonstration")
    print("=" * 40)
    
    detector = FakeCodeDetector()
    
    # Test the same data with different validation levels
    test_data = {
        "id": "maybe_valid",
        "name": "sample workflow",
        "status": "completed",
        "description": "This is a test workflow"
    }
    
    print(f"\nğŸ“Š Testing data with different validation levels:")
    print(f"Data: {json.dumps(test_data, indent=2)}")
    
    # Note: In the simplified demo, we can't easily change validation levels
    # but we can show how the same data would be analyzed
    result = detector.analyze_code_sample(test_data, "Multi-level validation test")
    
    print(f"\nğŸ’¡ Validation Level Insights:")
    print(f"   - Basic Level: Would be more permissive")
    print(f"   - Strict Level: Current analysis (shown above)")
    print(f"   - Paranoid Level: Would flag more issues")


def demonstrate_prevention_strategies():
    """Demonstrate prevention strategies for fake code."""
    
    print("\nğŸ›¡ï¸ Prevention Strategies Demonstration")
    print("=" * 45)
    
    print("\nğŸ“‹ Best Practices for Using Claude Code:")
    
    print("\n1. âœ… Clear and Specific Prompts:")
    print("   âŒ Bad: 'Create a workflow'")
    print("   âœ… Good: 'Create a GitHub Actions workflow for Python 3.11 that runs pytest and coverage'")
    
    print("\n2. âœ… Provide Complete Context:")
    print("   âŒ Bad: No context provided")
    print("   âœ… Good: Include project structure, dependencies, and requirements")
    
    print("\n3. âœ… Specify Exact Versions:")
    print("   âŒ Bad: 'Use the latest version'")
    print("   âœ… Good: 'Use Python 3.11.7, pytest 7.4.3, coverage 7.3.2'")
    
    print("\n4. âœ… Include Error Handling:")
    print("   âŒ Bad: No error handling specified")
    print("   âœ… Good: 'Include proper error handling and logging'")
    
    print("\n5. âœ… Define Success Criteria:")
    print("   âŒ Bad: 'Make it work'")
    print("   âœ… Good: 'Must pass all tests, achieve 90% coverage, complete in under 5 minutes'")


def main():
    """Main demonstration function."""
    
    try:
        demonstrate_fake_code_detection()
        demonstrate_validation_levels()
        demonstrate_prevention_strategies()
        
        print("\nğŸ¯ Summary")
        print("=" * 20)
        print("This demonstration shows how the uvmgr validation system can detect")
        print("fake or hallucinated code generated by AI assistants like Claude Code.")
        print("\nKey takeaways:")
        print("â€¢ Multi-layered validation catches different types of issues")
        print("â€¢ Suspicious patterns are automatically flagged")
        print("â€¢ Confidence scoring helps assess reliability")
        print("â€¢ Prevention strategies reduce hallucination risk")
        
    except Exception as e:
        print(f"âŒ Demonstration failed: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 