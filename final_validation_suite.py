#!/usr/bin/env python3
"""
Final validation suite for uvmgr core commands.
Tests only the enabled, working commands.
"""

import subprocess
import tempfile
import json
import time
from pathlib import Path
import sys

def run_command(cmd, cwd=None, timeout=30):
    """Run command and return result."""
    try:
        start_time = time.time()
        result = subprocess.run(
            cmd,
            cwd=cwd,
            capture_output=True,
            text=True,
            timeout=timeout
        )
        elapsed = time.time() - start_time
        return result.returncode, result.stdout, result.stderr, elapsed
    except subprocess.TimeoutExpired:
        return 1, "", "Command timed out", timeout
    except Exception as e:
        return 1, "", str(e), 0

class UvmgrFinalValidator:
    """Final validation for uvmgr system."""
    
    def __init__(self):
        self.results = {
            "command_tests": [],
            "telemetry_tests": [],
            "external_tests": [],
            "performance_tests": []
        }
        
    def run_all_tests(self):
        """Run complete validation suite."""
        print("üöÄ uvmgr Final Validation Suite")
        print("=" * 50)
        
        # 1. Test enabled commands
        print("\nüìã Testing Enabled Commands...")
        self.test_enabled_commands()
        
        # 2. Validate telemetry
        print("\nüî¨ Validating Telemetry System...")
        self.validate_telemetry()
        
        # 3. Test external projects
        print("\nüåç Testing External Project Integration...")
        self.test_external_projects()
        
        # 4. Performance check
        print("\n‚ö° Running Performance Tests...")
        self.test_performance()
        
        # Generate report
        return self.generate_report()
    
    def test_enabled_commands(self):
        """Test all currently enabled commands."""
        enabled_commands = [
            ("deps", "Dependency management"),
            ("build", "Build system"),
            ("tests", "Test execution"),
            ("cache", "Cache management"),
            ("lint", "Code quality"),
            ("otel", "OpenTelemetry"),
            ("guides", "Agent guides"),
            ("worktree", "Git worktree"),
            ("infodesign", "Information design"),
            ("mermaid", "Mermaid diagrams"),
        ]
        
        for cmd_name, desc in enabled_commands:
            exit_code, stdout, stderr, elapsed = run_command(["uvmgr", cmd_name, "--help"])
            success = exit_code == 0
            
            self.results["command_tests"].append({
                "command": cmd_name,
                "description": desc,
                "success": success,
                "exit_code": exit_code,
                "elapsed": elapsed,
                "has_output": len(stdout) > 0
            })
            
            status = "‚úÖ" if success else "‚ùå"
            print(f"  {status} {cmd_name} ({desc}) - {elapsed:.2f}s")
    
    def validate_telemetry(self):
        """Validate OTEL telemetry system."""
        # Run OTEL validation
        exit_code, stdout, stderr, elapsed = run_command(["uvmgr", "otel", "validate"])
        
        # Check for key telemetry indicators
        telemetry_checks = {
            "span_creation": "span creation" in stdout.lower(),
            "metrics_collection": "metrics collection" in stdout.lower(),
            "error_handling": "error handling" in stdout.lower(),
            "performance_tracking": "performance tracking" in stdout.lower(),
            "validation_passed": exit_code == 0 or "80.0%" in stdout
        }
        
        for check, passed in telemetry_checks.items():
            self.results["telemetry_tests"].append({
                "check": check,
                "passed": passed
            })
            
            status = "‚úÖ" if passed else "‚ùå"
            print(f"  {status} {check.replace('_', ' ').title()}")
        
        # Run OTEL status check
        exit_code, stdout, stderr, elapsed = run_command(["uvmgr", "otel", "status"])
        if exit_code == 0:
            self.results["telemetry_tests"].append({
                "check": "otel_status",
                "passed": True,
                "details": "OTEL status command working"
            })
            print(f"  ‚úÖ OTEL Status Command")
    
    def test_external_projects(self):
        """Test uvmgr in external Python projects."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test projects
            project_types = [
                ("minimal", self._create_minimal_project),
                ("library", self._create_library_project),
                ("cli_app", self._create_cli_project),
            ]
            
            for project_type, creator in project_types:
                project_path = Path(temp_dir) / project_type
                creator(project_path)
                
                # Test core commands in each project
                test_commands = [
                    (["uvmgr", "deps", "list"], "deps list"),
                    (["uvmgr", "lint", "check", "src"], "lint check"),
                    (["uvmgr", "cache", "status"], "cache status"),
                ]
                
                project_success = True
                for cmd, desc in test_commands:
                    exit_code, stdout, stderr, elapsed = run_command(cmd, cwd=project_path, timeout=15)
                    success = exit_code == 0
                    if not success:
                        project_success = False
                
                self.results["external_tests"].append({
                    "project_type": project_type,
                    "success": project_success,
                    "path": str(project_path)
                })
                
                status = "‚úÖ" if project_success else "‚ùå"
                print(f"  {status} {project_type} project integration")
    
    def test_performance(self):
        """Test command performance."""
        perf_tests = [
            (["uvmgr", "--help"], "help", 2.0),
            (["uvmgr", "deps", "--help"], "deps help", 2.0),
            (["uvmgr", "otel", "status"], "otel status", 3.0),
        ]
        
        for cmd, desc, max_time in perf_tests:
            exit_code, stdout, stderr, elapsed = run_command(cmd, timeout=10)
            success = exit_code == 0 and elapsed <= max_time
            
            self.results["performance_tests"].append({
                "command": " ".join(cmd),
                "description": desc,
                "elapsed": elapsed,
                "max_time": max_time,
                "passed": success
            })
            
            status = "‚úÖ" if success else "‚ùå"
            print(f"  {status} {desc} ({elapsed:.2f}s / {max_time}s)")
    
    def _create_minimal_project(self, path):
        """Create minimal Python project."""
        path.mkdir(parents=True)
        (path / "pyproject.toml").write_text("""
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "test-minimal"
version = "0.1.0"
dependencies = []
""")
        src = path / "src" / "test_minimal"
        src.mkdir(parents=True)
        (src / "__init__.py").write_text('__version__ = "0.1.0"')
        (src / "main.py").write_text('def main(): print("Hello")')
    
    def _create_library_project(self, path):
        """Create library project."""
        path.mkdir(parents=True)
        (path / "pyproject.toml").write_text("""
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "test-library"
version = "0.1.0"
dependencies = ["requests>=2.28.0"]

[project.optional-dependencies]
dev = ["pytest>=7.0.0", "ruff>=0.1.0"]
""")
        src = path / "src" / "test_library"
        src.mkdir(parents=True)
        (src / "__init__.py").write_text('from .core import process_data')
        (src / "core.py").write_text('''
def process_data(data):
    """Process input data."""
    return {"processed": data, "status": "ok"}
''')
    
    def _create_cli_project(self, path):
        """Create CLI application project."""
        path.mkdir(parents=True)
        (path / "pyproject.toml").write_text("""
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "test-cli"
version = "0.1.0"
dependencies = ["click>=8.0.0"]

[project.scripts]
testcli = "test_cli.main:cli"
""")
        src = path / "src" / "test_cli"
        src.mkdir(parents=True)
        (src / "__init__.py").write_text('')
        (src / "main.py").write_text('''
import click

@click.command()
@click.option("--name", default="World")
def cli(name):
    """Simple CLI tool."""
    click.echo(f"Hello, {name}!")
''')
    
    def generate_report(self):
        """Generate comprehensive report."""
        # Calculate metrics
        cmd_success = sum(1 for t in self.results["command_tests"] if t["success"])
        cmd_total = len(self.results["command_tests"])
        cmd_rate = cmd_success / cmd_total if cmd_total > 0 else 0
        
        tel_success = sum(1 for t in self.results["telemetry_tests"] if t.get("passed", False))
        tel_total = len(self.results["telemetry_tests"])
        tel_rate = tel_success / tel_total if tel_total > 0 else 0
        
        ext_success = sum(1 for t in self.results["external_tests"] if t["success"])
        ext_total = len(self.results["external_tests"])
        ext_rate = ext_success / ext_total if ext_total > 0 else 0
        
        perf_success = sum(1 for t in self.results["performance_tests"] if t["passed"])
        perf_total = len(self.results["performance_tests"])
        perf_rate = perf_success / perf_total if perf_total > 0 else 0
        
        overall_rate = (cmd_rate + tel_rate + ext_rate + perf_rate) / 4
        
        report = {
            "summary": {
                "command_success_rate": cmd_rate,
                "telemetry_success_rate": tel_rate,
                "external_success_rate": ext_rate,
                "performance_success_rate": perf_rate,
                "overall_success_rate": overall_rate,
                "meets_8020_threshold": overall_rate >= 0.80
            },
            "results": self.results,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        return report

def main():
    """Main validation function."""
    validator = UvmgrFinalValidator()
    report = validator.run_all_tests()
    
    # Print summary
    print("\n" + "=" * 50)
    print("üìä VALIDATION SUMMARY")
    print("=" * 50)
    
    summary = report["summary"]
    print(f"Command Tests:      {summary['command_success_rate']:.0%}")
    print(f"Telemetry Tests:    {summary['telemetry_success_rate']:.0%}")
    print(f"External Tests:     {summary['external_success_rate']:.0%}")
    print(f"Performance Tests:  {summary['performance_success_rate']:.0%}")
    print(f"Overall Success:    {summary['overall_success_rate']:.0%}")
    print(f"\n80/20 Threshold:    {'‚úÖ MET' if summary['meets_8020_threshold'] else '‚ùå NOT MET'}")
    
    # Save report
    with open("final_validation_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    print(f"\nüìÑ Report saved to: final_validation_report.json")
    
    return 0 if summary["meets_8020_threshold"] else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)